{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé§ Codename RVC Fork 4 - Modo CLI\n",
                "\n",
                "##### Notebook made by shiroug :shiba:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 1Ô∏è‚É£ Clonar Reposit√≥rio e Configurar Ambiente\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# === CLONAR O REPOSIT√ìRIO ===\n",
                "print(\"üì• Clonando reposit√≥rio...\")\n",
                "!git clone https://github.com/ShiromiyaG/codename-rvc-fork-4.git\n",
                "%cd codename-rvc-fork-4\n",
                "\n",
                "# === PREPARAR PYTHON 3.10 ===\n",
                "print(\"\\nüîÑ Configurando Python 3.10...\")\n",
                "!apt-get update -qq\n",
                "!apt-get install -y -qq python3.10 python3.10-dev python3.10-distutils libpython3.10-dev curl aria2\n",
                "\n",
                "# Atualizar alternativas para usar Python 3.10\n",
                "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
                "!update-alternatives --set python3 /usr/bin/python3.10\n",
                "\n",
                "# === INSTALAR UV ===\n",
                "print(\"\\nüì¶ Instalando gerenciador de pacotes UV...\")\n",
                "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
                "os.environ[\"PATH\"] += \":/root/.cargo/bin\"\n",
                "\n",
                "# Instalar pip e depend√™ncias\n",
                "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3\n",
                "!uv pip install --system -r requirements.txt\n",
                "\n",
                "print(\"\\n‚úÖ Configura√ß√£o conclu√≠da!\")\n",
                "!python3 --version"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 2Ô∏è‚É£ Baixar Pretrains Customizados (Hugging Face)\n",
                "\n",
                "# @markdown ### Gerador (G)\n",
                "G_url = \"\" # @param {type:\"string\"}\n",
                "G_filename = \"G_custom.pth\" # @param {type:\"string\"}\n",
                "\n",
                "# @markdown ### Discriminador (D)\n",
                "D_url = \"\" # @param {type:\"string\"}\n",
                "D_filename = \"D_custom.pth\" # @param {type:\"string\"}\n",
                "\n",
                "import subprocess\n",
                "from pathlib import Path\n",
                "\n",
                "PRETRAIN_DIR = Path(\"rvc/models/pretraineds/custom\")\n",
                "\n",
                "def download_file(url, output_dir, filename):\n",
                "    \"\"\"Baixa um arquivo focado em links do Hugging Face\"\"\"\n",
                "    if not url.strip():\n",
                "        return\n",
                "    \n",
                "    # L√≥gica Espec√≠fica para Hugging Face\n",
                "    if \"huggingface.co\" in url:\n",
                "        # Troca 'blob' (visualiza√ß√£o) por 'resolve' (download direto)\n",
                "        url = url.replace(\"/blob/\", \"/resolve/\")\n",
                "        \n",
                "        # Remove par√¢metros de query desnecess√°rios se existirem (ex: ?download=true)\n",
                "        if \"?\" in url:\n",
                "            url = url.split(\"?\")[0]\n",
                "            \n",
                "    # Cria o diret√≥rio se n√£o existir\n",
                "    output_dir.mkdir(parents=True, exist_ok=True)\n",
                "    full_path = output_dir / filename\n",
                "    \n",
                "    if full_path.exists():\n",
                "        print(f\"‚è≠Ô∏è {filename} j√° existe\")\n",
                "        return\n",
                "    \n",
                "    print(f\"üì• Baixando {filename} de: {url}\")\n",
                "    \n",
                "    # Executa o download usando aria2c\n",
                "    # -x 16 -s 16: M√∫ltiplas conex√µes para velocidade m√°xima\n",
                "    try:\n",
                "        subprocess.run(\n",
                "            ['aria2c', '-x', '16', '-s', '16', '-d', str(output_dir), '-o', filename, url],\n",
                "            check=True\n",
                "        )\n",
                "        if full_path.exists():\n",
                "            print(f\"‚úÖ {filename} baixado com sucesso!\")\n",
                "        else:\n",
                "            print(f\"‚ùå Falha ao baixar {filename}. Verifique o link.\")\n",
                "    except subprocess.CalledProcessError:\n",
                "        print(f\"‚ùå Erro na execu√ß√£o do download para {filename}\")\n",
                "\n",
                "# Execu√ß√£o\n",
                "if G_url:\n",
                "    download_file(G_url, PRETRAIN_DIR, G_filename)\n",
                "if D_url:\n",
                "    download_file(D_url, PRETRAIN_DIR, D_filename)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üéì FLUXO DE TREINO\n",
                "\n",
                "O pipeline de treino consiste em 3 etapas:\n",
                "1. **Preprocess** ‚Üí Preparar e limpar arquivos de √°udio\n",
                "2. **Extract** ‚Üí Extrair pitch (F0) e embeddings de voz  \n",
                "3. **Train** ‚Üí Treinar o modelo\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 4Ô∏è‚É£ Etapa 1: Preprocessar Dataset\n",
                "# @markdown Prepara os arquivos de √°udio para treino (corte, normaliza√ß√£o, etc.)\n",
                "# @markdown \n",
                "# @markdown > ‚ö†Ô∏è **Nota:** Se `CUT_MODE = \"Simple\"`, os √°udios ter√£o o sil√™ncio truncado automaticamente antes do preprocess.\n",
                "\n",
                "# @markdown ### Configura√ß√µes Obrigat√≥rias\n",
                "MODEL_NAME = \"meu_modelo_de_voz\"  # @param {type:\"string\"}\n",
                "DATASET_PATH = \"assets/datasets/meu_dataset\"  # @param {type:\"string\"}\n",
                "SAMPLE_RATE = 32000  # @param [24000, 32000, 40000, 48000] {type:\"raw\"}\n",
                "\n",
                "# @markdown ### Configura√ß√µes Opcionais\n",
                "CUT_MODE = \"Simple\"  # @param [\"Skip\", \"Simple\", \"Automatic\"]\n",
                "NORMALIZATION = \"post_lufs\"  # @param [\"none\", \"post_lufs\", \"post_peak\"]\n",
                "CHUNK_LEN = 3.0  # @param {type:\"slider\", min:0.5, max:5.0, step:0.5}\n",
                "\n",
                "# @markdown ### Configura√ß√µes de Truncar Sil√™ncio (apenas para Simple)\n",
                "# @markdown Baseado no \"Travar Sil√™ncio\" do Audacity\n",
                "SILENCE_THRESHOLD_DB = -50  # @param {type:\"slider\", min:-70, max:-20, step:5}\n",
                "MIN_SILENCE_DURATION = 0.5  # @param {type:\"slider\", min:0.1, max:2.0, step:0.1}\n",
                "KEEP_SILENCE = 0.3  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "from pydub import AudioSegment\n",
                "from pydub.silence import detect_nonsilent\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "def truncate_silence(audio_path, output_path, threshold_db=-50, min_silence_ms=500, keep_silence_ms=300):\n",
                "    \"\"\"\n",
                "    Remove sil√™ncio do in√≠cio e fim do √°udio.\n",
                "    Baseado nas configura√ß√µes do \"Travar Sil√™ncio\" do Audacity.\n",
                "    \n",
                "    Args:\n",
                "        audio_path: Caminho do √°udio original\n",
                "        output_path: Caminho para salvar o √°udio processado\n",
                "        threshold_db: Limiar em dB para detectar sil√™ncio (padr√£o: -50dB)\n",
                "        min_silence_ms: Dura√ß√£o m√≠nima de sil√™ncio em ms (padr√£o: 500ms)\n",
                "        keep_silence_ms: Quanto sil√™ncio manter nas bordas em ms (padr√£o: 300ms)\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Carregar √°udio\n",
                "        audio = AudioSegment.from_file(audio_path)\n",
                "        \n",
                "        # Detectar partes n√£o-silenciosas\n",
                "        nonsilent_ranges = detect_nonsilent(\n",
                "            audio,\n",
                "            min_silence_len=min_silence_ms,\n",
                "            silence_thresh=threshold_db\n",
                "        )\n",
                "        \n",
                "        if not nonsilent_ranges:\n",
                "            # √Åudio √© todo sil√™ncio, pular\n",
                "            return False\n",
                "        \n",
                "        # Pegar in√≠cio da primeira parte n√£o-silenciosa e fim da √∫ltima\n",
                "        start_ms = max(0, nonsilent_ranges[0][0] - keep_silence_ms)\n",
                "        end_ms = min(len(audio), nonsilent_ranges[-1][1] + keep_silence_ms)\n",
                "        \n",
                "        # Cortar o √°udio\n",
                "        trimmed_audio = audio[start_ms:end_ms]\n",
                "        \n",
                "        # Salvar\n",
                "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "        trimmed_audio.export(output_path, format=output_path.suffix[1:])\n",
                "        \n",
                "        return True\n",
                "    except Exception as e:\n",
                "        print(f\"   ‚ö†Ô∏è Erro ao processar {audio_path.name}: {e}\")\n",
                "        return False\n",
                "\n",
                "def process_dataset_silence(dataset_path, threshold_db, min_silence_sec, keep_silence_sec):\n",
                "    \"\"\"\n",
                "    Processa todos os √°udios do dataset, truncando sil√™ncio.\n",
                "    Cria uma c√≥pia tempor√°ria do dataset com os √°udios processados.\n",
                "    \"\"\"\n",
                "    dataset_path = Path(dataset_path)\n",
                "    temp_dataset = Path(f\"/tmp/dataset_trimmed_{dataset_path.name}\")\n",
                "    \n",
                "    # Limpar pasta tempor√°ria se existir\n",
                "    if temp_dataset.exists():\n",
                "        shutil.rmtree(temp_dataset)\n",
                "    temp_dataset.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    # Encontrar todos os arquivos de √°udio\n",
                "    audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a', '.opus'}\n",
                "    audio_files = []\n",
                "    for ext in audio_extensions:\n",
                "        audio_files.extend(dataset_path.rglob(f\"*{ext}\"))\n",
                "    \n",
                "    if not audio_files:\n",
                "        print(\"‚ö†Ô∏è Nenhum arquivo de √°udio encontrado no dataset!\")\n",
                "        return None\n",
                "    \n",
                "    print(f\"üîá Truncando sil√™ncio de {len(audio_files)} arquivos...\")\n",
                "    print(f\"   Limiar: {threshold_db}dB | Dura√ß√£o m√≠n: {min_silence_sec}s | Manter: {keep_silence_sec}s\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    min_silence_ms = int(min_silence_sec * 1000)\n",
                "    keep_silence_ms = int(keep_silence_sec * 1000)\n",
                "    \n",
                "    processed = 0\n",
                "    skipped = 0\n",
                "    \n",
                "    for audio_file in audio_files:\n",
                "        # Manter estrutura de pastas relativa\n",
                "        relative_path = audio_file.relative_to(dataset_path)\n",
                "        output_path = temp_dataset / relative_path\n",
                "        \n",
                "        if truncate_silence(audio_file, output_path, threshold_db, min_silence_ms, keep_silence_ms):\n",
                "            processed += 1\n",
                "        else:\n",
                "            skipped += 1\n",
                "        \n",
                "        # Mostrar progresso a cada 10 arquivos\n",
                "        if (processed + skipped) % 10 == 0:\n",
                "            print(f\"   Processados: {processed + skipped}/{len(audio_files)}\")\n",
                "    \n",
                "    print(f\"\\n‚úÖ Sil√™ncio truncado: {processed} arquivos processados, {skipped} ignorados\")\n",
                "    return str(temp_dataset)\n",
                "\n",
                "# === EXECUTAR PREPROCESSAMENTO ===\n",
                "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
                "print(f\"üìÇ Dataset: {DATASET_PATH}\")\n",
                "print(f\"üéµ Taxa de Amostragem: {SAMPLE_RATE}Hz\")\n",
                "print(f\"‚úÇÔ∏è Modo de Corte: {CUT_MODE}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Se o modo for Simple, truncar sil√™ncio primeiro\n",
                "final_dataset_path = DATASET_PATH\n",
                "\n",
                "if CUT_MODE == \"Simple\":\n",
                "    print(\"\\nüîá Modo Simple detectado - Truncando sil√™ncio do dataset...\\n\")\n",
                "    processed_path = process_dataset_silence(\n",
                "        DATASET_PATH,\n",
                "        threshold_db=SILENCE_THRESHOLD_DB,\n",
                "        min_silence_sec=MIN_SILENCE_DURATION,\n",
                "        keep_silence_sec=KEEP_SILENCE\n",
                "    )\n",
                "    if processed_path:\n",
                "        final_dataset_path = processed_path\n",
                "        print(f\"\\nüìÇ Usando dataset processado: {final_dataset_path}\\n\")\n",
                "    print(\"=\"*60)\n",
                "\n",
                "print(\"\\nüöÄ Iniciando preprocessamento CLI...\\n\")\n",
                "\n",
                "!python core.py preprocess \\\n",
                "    --model_name \"{MODEL_NAME}\" \\\n",
                "    --dataset_path \"{final_dataset_path}\" \\\n",
                "    --sample_rate {SAMPLE_RATE} \\\n",
                "    --cut_preprocess \"{CUT_MODE}\" \\\n",
                "    --normalization_mode \"{NORMALIZATION}\" \\\n",
                "    --chunk_len {CHUNK_LEN} \\\n",
                "    --loading_resampling \"ffmpeg\" \\\n",
                "    --lufs_range_finder True\n",
                "\n",
                "print(\"\\n‚úÖ Preprocessamento conclu√≠do!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 5Ô∏è‚É£ Etapa 2: Extrair Features\n",
                "# @markdown Extrai pitch (F0) e embeddings de voz dos √°udios preprocessados\n",
                "\n",
                "# @markdown ### Configura√ß√µes\n",
                "F0_METHOD = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\"]\n",
                "EMBEDDER = \"contentvec\"  # @param [\"contentvec\", \"spin_v1\", \"spin_v2\", \"custom\"]\n",
                "VOCODER_ARCH = \"hifi_refine\"  # @param [\"hifi_refine\", \"ringformer\", \"pcph_gan\"]\n",
                "\n",
                "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
                "print(f\"üé§ M√©todo F0: {F0_METHOD}\")\n",
                "print(f\"üîä Embedder: {EMBEDDER}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "!python core.py extract \\\n",
                "    --model_name \"{MODEL_NAME}\" \\\n",
                "    --sample_rate {SAMPLE_RATE} \\\n",
                "    --f0_method \"{F0_METHOD}\" \\\n",
                "    --embedder_model \"{EMBEDDER}\" \\\n",
                "    --vocoder_arch \"{VOCODER_ARCH}\" \\\n",
                "    --include_mutes 2 \\\n",
                "    --gpu \"0\"\n",
                "\n",
                "print(\"\\n‚úÖ Extra√ß√£o de features conclu√≠da!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 6Ô∏è‚É£ Etapa 3: Treinar Modelo\n",
                "# @markdown Treina o modelo RVC usando as features extra√≠das\n",
                "\n",
                "# @markdown ### Configura√ß√µes Obrigat√≥rias\n",
                "TOTAL_EPOCHS = 300  # @param {type:\"integer\"}\n",
                "BATCH_SIZE = 4  # @param {type:\"slider\", min:1, max:32, step:1}\n",
                "\n",
                "# @markdown ### Arquitetura\n",
                "VOCODER = \"HiFi-GAN\"  # @param [\"HiFi-GAN\", \"PCPH-GAN\", \"RefineGAN\", \"RingFormer_v1\", \"RingFormer_v2\"]\n",
                "ARCHITECTURE = \"RVC\"  # @param [\"RVC\", \"Fork/Applio\", \"Fork\"]\n",
                "OPTIMIZER = \"AdamW\"  # @param [\"AdamW BF16\", \"AdamW\", \"AdamSPD\", \"RAdam\", \"Ranger21\", \"DiffGrad\", \"Prodigy\"]\n",
                "\n",
                "# @markdown ### Modelo Pr√©-treinado\n",
                "USE_PRETRAINED = True  # @param {type:\"boolean\"}\n",
                "CUSTOM_PRETRAINED = False  # @param {type:\"boolean\"}\n",
                "G_PATH = \"rvc/models/pretraineds/custom/G_custom.pth\"  # @param {type:\"string\"}\n",
                "D_PATH = \"rvc/models/pretraineds/custom/D_custom.pth\"  # @param {type:\"string\"}\n",
                "\n",
                "# @markdown ### Configura√ß√µes de Salvamento\n",
                "SAVE_EVERY = 10  # @param {type:\"integer\"}\n",
                "SAVE_ONLY_LATEST = True  # @param {type:\"boolean\"}\n",
                "\n",
                "# @markdown ### Avan√ßado\n",
                "USE_WARMUP = False  # @param {type:\"boolean\"}\n",
                "WARMUP_EPOCHS = 10  # @param {type:\"integer\"}\n",
                "SPECTRAL_LOSS = \"L1 Mel Loss\"  # @param [\"L1 Mel Loss\", \"Multi-Scale Mel Loss\", \"Multi-Res STFT Loss\"]\n",
                "LR_SCHEDULER = \"exp decay step\"  # @param [\"exp decay step\", \"exp decay epoch\", \"cosine annealing\", \"none\"]\n",
                "VITS_2_MODE = False # @param {type:\"boolean\"}\n",
                "CLEANUP = True # @param {type:\"boolean\"}\n",
                "\n",
                "\n",
                "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
                "print(f\"üéµ Taxa de Amostragem: {SAMPLE_RATE}Hz\")\n",
                "print(f\"üî¢ Total de Epochs: {TOTAL_EPOCHS}\")\n",
                "print(f\"üì¶ Tamanho do Batch: {BATCH_SIZE}\")\n",
                "print(f\"üéõÔ∏è Vocoder: {VOCODER}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Montar comando com argumentos opcionais\n",
                "cmd = f\"\"\"python core.py train \\\\\n",
                "    --model_name \"{MODEL_NAME}\" \\\\\n",
                "    --sample_rate {SAMPLE_RATE} \\\\\n",
                "    --total_epoch_count {TOTAL_EPOCHS} \\\\\n",
                "    --batch_size {BATCH_SIZE} \\\\\n",
                "    --vocoder \"{VOCODER}\" \\\\\n",
                "    --architecture \"{ARCHITECTURE}\" \\\\\n",
                "    --optimizer \"{OPTIMIZER}\" \\\\\n",
                "    --epoch_save_frequency {SAVE_EVERY} \\\\\n",
                "    --save_only_latest_net_models {str(SAVE_ONLY_LATEST)} \\\\\n",
                "    --save_weight_models True \\\\\n",
                "    --pretrained {str(USE_PRETRAINED)} \\\\\n",
                "    --custom_pretrained {str(CUSTOM_PRETRAINED)} \\\\\n",
                "    --use_warmup {str(USE_WARMUP)} \\\\\n",
                "    --warmup_duration {WARMUP_EPOCHS} \\\\\n",
                "    --spectral_loss \"{SPECTRAL_LOSS}\" \\\\\n",
                "    --lr_scheduler \"{LR_SCHEDULER}\" \\\\\n",
                "    --use_validation False \\\\\n",
                "    --vits_2_mode {str(VITS_2_MODE)} \\\\\n",
                "    --cleanup {str(CLEANUP)} \\\\\n",
                "    --gpu \"0\"\"\"\n",
                "\n",
                "# Adicionar caminhos de pretrain se usando custom\n",
                "if CUSTOM_PRETRAINED and G_PATH:\n",
                "    cmd += f' --g_pretrained_path \"{G_PATH}\"'\n",
                "if CUSTOM_PRETRAINED and D_PATH:\n",
                "    cmd += f' --d_pretrained_path \"{D_PATH}\"'\n",
                "\n",
                "print(\"\\nüöÄ Iniciando treino...\")\n",
                "print(\"üí° Dica: Use Ctrl+C para parar o treino a qualquer momento\\n\")\n",
                "!{cmd}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 7Ô∏è‚É£ Gerar Arquivo Index\n",
                "# @markdown Cria um arquivo de √≠ndice para o modelo treinado (usado na infer√™ncia)\n",
                "\n",
                "INDEX_ALGORITHM = \"Auto\"  # @param [\"Auto\", \"Faiss\", \"KMeans\"]\n",
                "\n",
                "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "!python core.py index \\\n",
                "    --model_name \"{MODEL_NAME}\" \\\n",
                "    --index_algorithm \"{INDEX_ALGORITHM}\"\n",
                "\n",
                "print(\"\\n‚úÖ Arquivo index gerado!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# üéôÔ∏è INFER√äNCIA (Convers√£o de Voz)\n",
                "\n",
                "Converta √°udios usando seu modelo treinado.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 8Ô∏è‚É£ Infer√™ncia de Arquivo √önico\n",
                "# @markdown Converte um √∫nico arquivo de √°udio\n",
                "\n",
                "# @markdown ### Caminhos Obrigat√≥rios\n",
                "INPUT_PATH = \"/kaggle/input/audio/musica.wav\"  # @param {type:\"string\"}\n",
                "OUTPUT_PATH = \"/kaggle/working/output.wav\"  # @param {type:\"string\"}\n",
                "MODEL_PATH = \"logs/meu_modelo_de_voz/meu_modelo_de_voz.pth\"  # @param {type:\"string\"}\n",
                "INDEX_PATH = \"logs/meu_modelo_de_voz/added_*.index\"  # @param {type:\"string\"}\n",
                "\n",
                "# @markdown ### Configura√ß√µes de Infer√™ncia\n",
                "PITCH = 0  # @param {type:\"slider\", min:-24, max:24, step:1}\n",
                "F0_METHOD = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\"]\n",
                "INDEX_RATE = 0.5  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
                "PROTECT = 0.33  # @param {type:\"slider\", min:0.0, max:0.5, step:0.05}\n",
                "\n",
                "# @markdown ### Configura√ß√µes de √Åudio\n",
                "SPLIT_AUDIO = False  # @param {type:\"boolean\"}\n",
                "CLEAN_AUDIO = False  # @param {type:\"boolean\"}\n",
                "F0_AUTOTUNE = False  # @param {type:\"boolean\"}\n",
                "EXPORT_FORMAT = \"WAV\"  # @param [\"WAV\", \"MP3\", \"FLAC\", \"OGG\", \"M4A\"]\n",
                "\n",
                "print(f\"üéµ Entrada: {INPUT_PATH}\")\n",
                "print(f\"üíæ Sa√≠da: {OUTPUT_PATH}\")\n",
                "print(f\"üé§ Modelo: {MODEL_PATH}\")\n",
                "print(f\"üéõÔ∏è Pitch: {PITCH:+d} semitons\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "!python core.py infer \\\n",
                "    --input_path \"{INPUT_PATH}\" \\\n",
                "    --output_path \"{OUTPUT_PATH}\" \\\n",
                "    --pth_path \"{MODEL_PATH}\" \\\n",
                "    --index_path \"{INDEX_PATH}\" \\\n",
                "    --pitch {PITCH} \\\n",
                "    --f0_method \"{F0_METHOD}\" \\\n",
                "    --index_rate {INDEX_RATE} \\\n",
                "    --protect {PROTECT} \\\n",
                "    --split_audio {str(SPLIT_AUDIO)} \\\n",
                "    --clean_audio {str(CLEAN_AUDIO)} \\\n",
                "    --f0_autotune {str(F0_AUTOTUNE)} \\\n",
                "    --export_format \"{EXPORT_FORMAT}\"\n",
                "\n",
                "print(f\"\\n‚úÖ Sa√≠da salva em: {OUTPUT_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellView": "form",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# @title 9Ô∏è‚É£ Infer√™ncia em Lote\n",
                "# @markdown Converte m√∫ltiplos arquivos de √°udio de uma pasta\n",
                "\n",
                "# @markdown ### Caminhos Obrigat√≥rios\n",
                "INPUT_FOLDER = \"/kaggle/input/musicas/\"  # @param {type:\"string\"}\n",
                "OUTPUT_FOLDER = \"/kaggle/working/convertidos/\"  # @param {type:\"string\"}\n",
                "MODEL_PATH = \"logs/meu_modelo_de_voz/meu_modelo_de_voz.pth\"  # @param {type:\"string\"}\n",
                "INDEX_PATH = \"logs/meu_modelo_de_voz/added_*.index\"  # @param {type:\"string\"}\n",
                "\n",
                "# @markdown ### Configura√ß√µes (mesmas da infer√™ncia √∫nica)\n",
                "PITCH = 0  # @param {type:\"slider\", min:-24, max:24, step:1}\n",
                "F0_METHOD = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\"]\n",
                "INDEX_RATE = 0.5  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
                "EXPORT_FORMAT = \"WAV\"  # @param [\"WAV\", \"MP3\", \"FLAC\", \"OGG\", \"M4A\"]\n",
                "\n",
                "import os\n",
                "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
                "\n",
                "print(f\"üìÇ Pasta de entrada: {INPUT_FOLDER}\")\n",
                "print(f\"üìÇ Pasta de sa√≠da: {OUTPUT_FOLDER}\")\n",
                "print(f\"üé§ Modelo: {MODEL_PATH}\")\n",
                "print(f\"üéõÔ∏è Pitch: {PITCH:+d} semitons\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "!python core.py batch_infer \\\n",
                "    --input_folder \"{INPUT_FOLDER}\" \\\n",
                "    --output_folder \"{OUTPUT_FOLDER}\" \\\n",
                "    --pth_path \"{MODEL_PATH}\" \\\n",
                "    --index_path \"{INDEX_PATH}\" \\\n",
                "    --pitch {PITCH} \\\n",
                "    --f0_method \"{F0_METHOD}\" \\\n",
                "    --index_rate {INDEX_RATE} \\\n",
                "    --export_format \"{EXPORT_FORMAT}\"\n",
                "\n",
                "print(f\"\\n‚úÖ Todos os arquivos convertidos! Confira: {OUTPUT_FOLDER}\")"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
