{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nnu-28SBn_M"
      },
      "source": [
        "# üé§ Codename RVC Fork 4 - Modo CLI (Google Colab)\n",
        "\n",
        "##### Notebook made by shiroug :shiba:\n",
        "\n",
        "> üìÅ **Esta vers√£o tem suporte ao Google Drive** para salvar seus modelos e datasets!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HVcY9LQfBn_N"
      },
      "outputs": [],
      "source": [
        "# @title 1Ô∏è‚É£ Montar Google Drive e Clonar Reposit√≥rio\n",
        "# @markdown Monta o Drive, clona o reposit√≥rio e cria symlinks para persist√™ncia\n",
        "\n",
        "MOUNT_DRIVE = True  # @param {type:\"boolean\"}\n",
        "DRIVE_FOLDER = \"codename-rvc\"  # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "%cd /content\n",
        "\n",
        "DRIVE_PATH = None\n",
        "\n",
        "# === MONTAR GOOGLE DRIVE ===\n",
        "if MOUNT_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    DRIVE_PATH = Path(f\"/content/drive/MyDrive/{DRIVE_FOLDER}\")\n",
        "    DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Criar subpastas no Drive\n",
        "    (DRIVE_PATH / \"datasets\").mkdir(exist_ok=True)\n",
        "    (DRIVE_PATH / \"logs\").mkdir(exist_ok=True)  # Modelos treinados\n",
        "    (DRIVE_PATH / \"pretrains\").mkdir(exist_ok=True)\n",
        "    (DRIVE_PATH / \"outputs\").mkdir(exist_ok=True)\n",
        "\n",
        "    print(f\"‚úÖ Google Drive montado em: {DRIVE_PATH}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Drive n√£o montado. Arquivos ser√£o perdidos ao desconectar.\")\n",
        "\n",
        "# === CLONAR REPOSIT√ìRIO ===\n",
        "print(\"\\nüì• Clonando reposit√≥rio...\")\n",
        "!git clone https://github.com/ShiromiyaG/codename-rvc-fork-4.git\n",
        "%cd codename-rvc-fork-4\n",
        "\n",
        "# === CRIAR SYMLINKS PARA O DRIVE ===\n",
        "if MOUNT_DRIVE and DRIVE_PATH:\n",
        "    print(\"\\nüîó Criando symlinks para o Drive...\")\n",
        "\n",
        "    # Symlink logs/ -> Drive/logs/ (modelos treinados)\n",
        "    logs_local = Path(\"logs\")\n",
        "    logs_drive = DRIVE_PATH / \"logs\"\n",
        "    if logs_local.exists() or logs_local.is_symlink():\n",
        "        if logs_local.is_symlink():\n",
        "            logs_local.unlink()\n",
        "        else:\n",
        "            shutil.rmtree(logs_local)\n",
        "    os.symlink(logs_drive, logs_local)\n",
        "    print(f\"   ‚úÖ logs/ -> {logs_drive}\")\n",
        "\n",
        "    # Symlink assets/datasets/ -> Drive/datasets/\n",
        "    datasets_local = Path(\"assets/datasets\")\n",
        "    datasets_drive = DRIVE_PATH / \"datasets\"\n",
        "    datasets_local.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if datasets_local.exists() or datasets_local.is_symlink():\n",
        "        if datasets_local.is_symlink():\n",
        "            datasets_local.unlink()\n",
        "        else:\n",
        "            shutil.rmtree(datasets_local)\n",
        "    os.symlink(datasets_drive, datasets_local)\n",
        "    print(f\"   ‚úÖ assets/datasets/ -> {datasets_drive}\")\n",
        "\n",
        "    # Symlink rvc/models/pretraineds/custom/ -> Drive/pretrains/\n",
        "    pretrains_local = Path(\"rvc/models/pretraineds/custom\")\n",
        "    pretrains_drive = DRIVE_PATH / \"pretrains\"\n",
        "    pretrains_local.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if pretrains_local.exists() or pretrains_local.is_symlink():\n",
        "        if pretrains_local.is_symlink():\n",
        "            pretrains_local.unlink()\n",
        "        else:\n",
        "            shutil.rmtree(pretrains_local)\n",
        "    os.symlink(pretrains_drive, pretrains_local)\n",
        "    print(f\"   ‚úÖ rvc/models/pretraineds/custom/ -> {pretrains_drive}\")\n",
        "\n",
        "    print(\"\\nüìÅ Estrutura no Drive:\")\n",
        "    print(f\"   {DRIVE_PATH}/\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ datasets/   <- Coloque seus √°udios aqui\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ logs/       <- Modelos treinados (autom√°tico)\")\n",
        "    print(f\"   ‚îú‚îÄ‚îÄ pretrains/  <- Pretrains G/D custom\")\n",
        "    print(f\"   ‚îî‚îÄ‚îÄ outputs/    <- √Åudios convertidos\")\n",
        "\n",
        "# === INSTALAR DEPEND√äNCIAS ===\n",
        "print(\"\\nüîÑ Configurando Python 3.10...\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq python3.10 python3.10-dev python3.10-distutils libpython3.10-dev curl aria2\n",
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!update-alternatives --set python3 /usr/bin/python3.10\n",
        "\n",
        "print(\"\\nüì¶ Instalando depend√™ncias...\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "os.environ[\"PATH\"] += \":/root/.cargo/bin\"\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3\n",
        "!uv pip install --system -r requirements.txt\n",
        "!uv pip install ring-attention-pytorch\n",
        "\n",
        "print(\"\\n‚úÖ Configura√ß√£o conclu√≠da!\")\n",
        "!python3 --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bOoJimx-Bn_O"
      },
      "outputs": [],
      "source": [
        "# @title 2Ô∏è‚É£ Baixar Pretrains Customizados (Hugging Face)\n",
        "\n",
        "# @markdown ### Gerador (G)\n",
        "G_url = \"\" # @param {type:\"string\"}\n",
        "G_filename = \"G_custom.pth\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Discriminador (D)\n",
        "D_url = \"\" # @param {type:\"string\"}\n",
        "D_filename = \"D_custom.pth\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Salvar no Google Drive?\n",
        "SAVE_TO_DRIVE = True # @param {type:\"boolean\"}\n",
        "\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Escolher pasta de destino\n",
        "if SAVE_TO_DRIVE and DRIVE_PATH:\n",
        "    PRETRAIN_DIR = DRIVE_PATH / \"pretrains\"\n",
        "else:\n",
        "    PRETRAIN_DIR = Path(\"rvc/models/pretraineds/custom\")\n",
        "\n",
        "def download_file(url, output_dir, filename):\n",
        "    \"\"\"Baixa um arquivo focado em links do Hugging Face\"\"\"\n",
        "    if not url.strip():\n",
        "        return\n",
        "\n",
        "    if \"huggingface.co\" in url:\n",
        "        url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        if \"?\" in url:\n",
        "            url = url.split(\"?\")[0]\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    full_path = output_dir / filename\n",
        "\n",
        "    if full_path.exists():\n",
        "        print(f\"‚è≠Ô∏è {filename} j√° existe\")\n",
        "        return\n",
        "\n",
        "    print(f\"üì• Baixando {filename}...\")\n",
        "    !wget -q -O \"{full_path}\" \"{url}\"\n",
        "\n",
        "    if full_path.exists():\n",
        "        print(f\"‚úÖ {filename} baixado em: {full_path}\")\n",
        "\n",
        "if G_url:\n",
        "    download_file(G_url, PRETRAIN_DIR, G_filename)\n",
        "if D_url:\n",
        "    download_file(D_url, PRETRAIN_DIR, D_filename)\n",
        "\n",
        "# Criar symlink para o projeto se salvou no Drive\n",
        "if SAVE_TO_DRIVE and DRIVE_PATH:\n",
        "    local_pretrain = Path(\"rvc/models/pretraineds/custom\")\n",
        "    local_pretrain.mkdir(parents=True, exist_ok=True)\n",
        "    for f in PRETRAIN_DIR.glob(\"*.pth\"):\n",
        "        dest = local_pretrain / f.name\n",
        "        if not dest.exists():\n",
        "            !cp \"{f}\" \"{dest}\"\n",
        "            print(f\"üìã Copiado {f.name} para projeto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DojcHzGQBn_O"
      },
      "source": [
        "---\n",
        "# üéì FLUXO DE TREINO\n",
        "\n",
        "O pipeline de treino consiste em 3 etapas:\n",
        "1. **Preprocess** ‚Üí Preparar e limpar arquivos de √°udio\n",
        "2. **Extract** ‚Üí Extrair pitch (F0) e embeddings de voz  \n",
        "3. **Train** ‚Üí Treinar o modelo\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6tUovJKYBn_O"
      },
      "outputs": [],
      "source": [
        "# @title 3Ô∏è‚É£ Etapa 1: Preprocessar Dataset\n",
        "# @markdown Prepara os arquivos de √°udio para treino\n",
        "# @markdown\n",
        "# @markdown > ‚ö†Ô∏è **Nota:** Se `CUT_MODE = \"Simple\"`, os √°udios ter√£o o sil√™ncio truncado automaticamente.\n",
        "\n",
        "# @markdown ### Configura√ß√µes Obrigat√≥rias\n",
        "MODEL_NAME = \"meu_modelo\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Origem do Dataset\n",
        "USE_DRIVE_DATASET = True  # @param {type:\"boolean\"}\n",
        "DATASET_NAME = \"meu_dataset\"  # @param {type:\"string\"}\n",
        "\n",
        "SAMPLE_RATE = 32000  # @param [24000, 32000, 40000, 48000] {type:\"raw\"}\n",
        "\n",
        "# @markdown ### Configura√ß√µes Opcionais\n",
        "CUT_MODE = \"Simple\"  # @param [\"Skip\", \"Simple\", \"Automatic\"]\n",
        "NORMALIZATION = \"post_lufs\"  # @param [\"none\", \"post_lufs\", \"post_peak\"]\n",
        "CHUNK_LEN = 3.0  # @param {type:\"slider\", min:0.5, max:5.0, step:0.5}\n",
        "\n",
        "# @markdown ### Truncar Sil√™ncio (apenas para Simple)\n",
        "SILENCE_THRESHOLD_DB = -50  # @param {type:\"slider\", min:-70, max:-20, step:5}\n",
        "MIN_SILENCE_DURATION = 0.5  # @param {type:\"slider\", min:0.1, max:2.0, step:0.1}\n",
        "KEEP_SILENCE = 0.3  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_nonsilent\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Determinar caminho do dataset\n",
        "if USE_DRIVE_DATASET and DRIVE_PATH:\n",
        "    DATASET_PATH = str(DRIVE_PATH / \"datasets\" / DATASET_NAME)\n",
        "else:\n",
        "    DATASET_PATH = f\"assets/datasets/{DATASET_NAME}\"\n",
        "\n",
        "def truncate_silence(audio_path, output_path, threshold_db=-50, min_silence_ms=500, keep_silence_ms=300):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        nonsilent_ranges = detect_nonsilent(audio, min_silence_len=min_silence_ms, silence_thresh=threshold_db)\n",
        "\n",
        "        if not nonsilent_ranges:\n",
        "            return False\n",
        "\n",
        "        start_ms = max(0, nonsilent_ranges[0][0] - keep_silence_ms)\n",
        "        end_ms = min(len(audio), nonsilent_ranges[-1][1] + keep_silence_ms)\n",
        "\n",
        "        trimmed_audio = audio[start_ms:end_ms]\n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        trimmed_audio.export(output_path, format=output_path.suffix[1:])\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Erro: {audio_path.name}: {e}\")\n",
        "        return False\n",
        "\n",
        "def process_dataset_silence(dataset_path, threshold_db, min_silence_sec, keep_silence_sec):\n",
        "    dataset_path = Path(dataset_path)\n",
        "    temp_dataset = Path(f\"/tmp/dataset_trimmed_{dataset_path.name}\")\n",
        "\n",
        "    if temp_dataset.exists():\n",
        "        shutil.rmtree(temp_dataset)\n",
        "    temp_dataset.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    audio_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a', '.opus'}\n",
        "    audio_files = []\n",
        "    for ext in audio_extensions:\n",
        "        audio_files.extend(dataset_path.rglob(f\"*{ext}\"))\n",
        "\n",
        "    if not audio_files:\n",
        "        print(\"‚ö†Ô∏è Nenhum arquivo de √°udio encontrado!\")\n",
        "        return None\n",
        "\n",
        "    print(f\"üîá Truncando sil√™ncio de {len(audio_files)} arquivos...\")\n",
        "\n",
        "    min_silence_ms = int(min_silence_sec * 1000)\n",
        "    keep_silence_ms = int(keep_silence_sec * 1000)\n",
        "\n",
        "    processed = 0\n",
        "    for audio_file in audio_files:\n",
        "        relative_path = audio_file.relative_to(dataset_path)\n",
        "        output_path = temp_dataset / relative_path\n",
        "        if truncate_silence(audio_file, output_path, threshold_db, min_silence_ms, keep_silence_ms):\n",
        "            processed += 1\n",
        "\n",
        "    print(f\"‚úÖ {processed} arquivos processados\")\n",
        "    return str(temp_dataset)\n",
        "\n",
        "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
        "print(f\"üìÇ Dataset: {DATASET_PATH}\")\n",
        "print(f\"üéµ Sample Rate: {SAMPLE_RATE}Hz\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_dataset_path = DATASET_PATH\n",
        "\n",
        "if CUT_MODE == \"Simple\":\n",
        "    print(\"\\nüîá Truncando sil√™ncio...\")\n",
        "    processed_path = process_dataset_silence(\n",
        "        DATASET_PATH,\n",
        "        threshold_db=SILENCE_THRESHOLD_DB,\n",
        "        min_silence_sec=MIN_SILENCE_DURATION,\n",
        "        keep_silence_sec=KEEP_SILENCE\n",
        "    )\n",
        "    if processed_path:\n",
        "        final_dataset_path = processed_path\n",
        "\n",
        "print(\"\\nüöÄ Iniciando preprocessamento...\\n\")\n",
        "\n",
        "!python core.py preprocess \\\n",
        "    --model_name \"{MODEL_NAME}\" \\\n",
        "    --dataset_path \"{final_dataset_path}\" \\\n",
        "    --sample_rate {SAMPLE_RATE} \\\n",
        "    --cut_preprocess \"{CUT_MODE}\" \\\n",
        "    --normalization_mode \"{NORMALIZATION}\" \\\n",
        "    --chunk_len {CHUNK_LEN} \\\n",
        "    --loading_resampling \"ffmpeg\" \\\n",
        "    --lufs_range_finder True\n",
        "\n",
        "print(\"\\n‚úÖ Preprocessamento conclu√≠do!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWls0lKTBn_P"
      },
      "outputs": [],
      "source": [
        "# @title 4Ô∏è‚É£ Etapa 2: Extrair Features\n",
        "# @markdown Extrai pitch (F0) e embeddings de voz\n",
        "\n",
        "F0_METHOD = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\"]\n",
        "EMBEDDER = \"contentvec\"  # @param [\"contentvec\", \"spin_v1\", \"spin_v2\", \"custom\"]\n",
        "VOCODER_ARCH = \"hifi_refine\"  # @param [\"hifi_refine\", \"ringformer\", \"pcph_gan\"]\n",
        "\n",
        "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
        "print(f\"üé§ F0: {F0_METHOD} | Embedder: {EMBEDDER}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python core.py extract \\\n",
        "    --model_name \"{MODEL_NAME}\" \\\n",
        "    --sample_rate {SAMPLE_RATE} \\\n",
        "    --f0_method \"{F0_METHOD}\" \\\n",
        "    --embedder_model \"{EMBEDDER}\" \\\n",
        "    --vocoder_arch \"{VOCODER_ARCH}\" \\\n",
        "    --include_mutes 2 \\\n",
        "    --gpu \"0\"\n",
        "\n",
        "print(\"\\n‚úÖ Extra√ß√£o conclu√≠da!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zSYOox6ZBn_P"
      },
      "outputs": [],
      "source": [
        "# @title 5Ô∏è‚É£ Etapa 3: Treinar Modelo\n",
        "\n",
        "# @markdown ### Configura√ß√µes\n",
        "TOTAL_EPOCHS = 300  # @param {type:\"integer\"}\n",
        "BATCH_SIZE = 8  # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "\n",
        "# @markdown ### Arquitetura\n",
        "VOCODER = \"HiFi-GAN\"  # @param [\"HiFi-GAN\", \"PCPH-GAN\", \"RefineGAN\", \"RingFormer_v1\", \"RingFormer_v2\"]\n",
        "ARCHITECTURE = \"RVC\"  # @param [\"RVC\", \"Fork/Applio\", \"Fork\"]\n",
        "OPTIMIZER = \"AdamW\"  # @param [\"AdamW BF16\", \"AdamW\", \"AdamSPD\", \"RAdam\", \"Ranger21\", \"DiffGrad\", \"Prodigy\"]\n",
        "\n",
        "# @markdown ### Modelo Pr√©-treinado\n",
        "USE_PRETRAINED = True  # @param {type:\"boolean\"}\n",
        "CUSTOM_PRETRAINED = False  # @param {type:\"boolean\"}\n",
        "G_PATH = \"rvc/models/pretraineds/custom/G_custom.pth\"  # @param {type:\"string\"}\n",
        "D_PATH = \"rvc/models/pretraineds/custom/D_custom.pth\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Salvamento\n",
        "SAVE_EVERY = 10  # @param {type:\"integer\"}\n",
        "SAVE_ONLY_LATEST = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ### Avan√ßado\n",
        "USE_WARMUP = False  # @param {type:\"boolean\"}\n",
        "WARMUP_EPOCHS = 10  # @param {type:\"integer\"}\n",
        "SPECTRAL_LOSS = \"L1 Mel Loss\"  # @param [\"L1 Mel Loss\", \"Multi-Scale Mel Loss\", \"Multi-Res STFT Loss\"]\n",
        "LR_SCHEDULER = \"exp decay step\"  # @param [\"exp decay step\", \"exp decay epoch\", \"cosine annealing\", \"none\"]\n",
        "VITS_2_MODE = False # @param {type:\"boolean\"}\n",
        "CLEANUP = True # @param {type:\"boolean\"}\n",
        "\n",
        "print(f\"üìÇ Modelo: {MODEL_NAME}\")\n",
        "print(f\"üî¢ Epochs: {TOTAL_EPOCHS} | Batch: {BATCH_SIZE}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "cmd = f\"\"\"python core.py train \\\\\n",
        "    --model_name \"{MODEL_NAME}\" \\\\\n",
        "    --sample_rate {SAMPLE_RATE} \\\\\n",
        "    --total_epoch_count {TOTAL_EPOCHS} \\\\\n",
        "    --batch_size {BATCH_SIZE} \\\\\n",
        "    --vocoder \"{VOCODER}\" \\\\\n",
        "    --architecture \"{ARCHITECTURE}\" \\\\\n",
        "    --optimizer \"{OPTIMIZER}\" \\\\\n",
        "    --epoch_save_frequency {SAVE_EVERY} \\\\\n",
        "    --save_only_latest_net_models {str(SAVE_ONLY_LATEST)} \\\\\n",
        "    --save_weight_models True \\\\\n",
        "    --pretrained {str(USE_PRETRAINED)} \\\\\n",
        "    --custom_pretrained {str(CUSTOM_PRETRAINED)} \\\\\n",
        "    --use_warmup {str(USE_WARMUP)} \\\\\n",
        "    --warmup_duration {WARMUP_EPOCHS} \\\\\n",
        "    --spectral_loss \"{SPECTRAL_LOSS}\" \\\\\n",
        "    --lr_scheduler \"{LR_SCHEDULER}\" \\\\\n",
        "    --use_validation False \\\\\n",
        "    --vits_2_mode {str(VITS_2_MODE)} \\\\\n",
        "    --cleanup {str(CLEANUP)} \\\\\n",
        "    --gpu \"0\"\"\"\n",
        "\n",
        "if CUSTOM_PRETRAINED and G_PATH:\n",
        "    cmd += f' --g_pretrained_path \"{G_PATH}\"'\n",
        "if CUSTOM_PRETRAINED and D_PATH:\n",
        "    cmd += f' --d_pretrained_path \"{D_PATH}\"'\n",
        "\n",
        "print(\"\\nüöÄ Iniciando treino...\")\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ej-B2HP9Bn_P"
      },
      "outputs": [],
      "source": [
        "# @title 6Ô∏è‚É£ Gerar Index e Salvar no Drive\n",
        "\n",
        "INDEX_ALGORITHM = \"Auto\"  # @param [\"Auto\", \"Faiss\", \"KMeans\"]\n",
        "SAVE_MODEL_TO_DRIVE = True  # @param {type:\"boolean\"}\n",
        "\n",
        "print(f\"üìÇ Gerando index para: {MODEL_NAME}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python core.py index \\\n",
        "    --model_name \"{MODEL_NAME}\" \\\n",
        "    --index_algorithm \"{INDEX_ALGORITHM}\"\n",
        "\n",
        "print(\"\\n‚úÖ Index gerado!\")\n",
        "\n",
        "# Copiar modelo para o Drive\n",
        "if SAVE_MODEL_TO_DRIVE and DRIVE_PATH:\n",
        "    import shutil\n",
        "    from pathlib import Path\n",
        "\n",
        "    model_log_dir = Path(f\"logs/{MODEL_NAME}\")\n",
        "    drive_model_dir = DRIVE_PATH / \"models\" / MODEL_NAME\n",
        "\n",
        "    if model_log_dir.exists():\n",
        "        print(f\"\\nüíæ Copiando modelo para Google Drive...\")\n",
        "\n",
        "        drive_model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Copiar arquivos .pth e .index\n",
        "        for f in model_log_dir.glob(\"*.pth\"):\n",
        "            shutil.copy2(f, drive_model_dir / f.name)\n",
        "            print(f\"   ‚úÖ {f.name}\")\n",
        "\n",
        "        for f in model_log_dir.glob(\"*.index\"):\n",
        "            shutil.copy2(f, drive_model_dir / f.name)\n",
        "            print(f\"   ‚úÖ {f.name}\")\n",
        "\n",
        "        print(f\"\\nüìÇ Modelo salvo em: {drive_model_dir}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Pasta do modelo n√£o encontrada: {model_log_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg8grj4hBn_Q"
      },
      "source": [
        "---\n",
        "# üéôÔ∏è INFER√äNCIA (Convers√£o de Voz)\n",
        "\n",
        "Converta √°udios usando seu modelo treinado.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PB5ee77JBn_Q"
      },
      "outputs": [],
      "source": [
        "# @title 7Ô∏è‚É£ Carregar Modelo do Drive\n",
        "# @markdown Use esta c√©lula para carregar um modelo salvo anteriormente\n",
        "\n",
        "LOAD_MODEL_NAME = \"meu_modelo\"  # @param {type:\"string\"}\n",
        "\n",
        "if DRIVE_PATH:\n",
        "    import shutil\n",
        "    from pathlib import Path\n",
        "\n",
        "    drive_model_dir = DRIVE_PATH / \"models\" / LOAD_MODEL_NAME\n",
        "    local_model_dir = Path(f\"logs/{LOAD_MODEL_NAME}\")\n",
        "\n",
        "    if drive_model_dir.exists():\n",
        "        print(f\"üìÇ Carregando modelo do Drive: {LOAD_MODEL_NAME}\")\n",
        "\n",
        "        local_model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for f in drive_model_dir.glob(\"*\"):\n",
        "            if f.suffix in ['.pth', '.index']:\n",
        "                shutil.copy2(f, local_model_dir / f.name)\n",
        "                print(f\"   ‚úÖ {f.name}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Modelo carregado em: {local_model_dir}\")\n",
        "\n",
        "        # Atualizar vari√°veis\n",
        "        MODEL_NAME = LOAD_MODEL_NAME\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Modelo n√£o encontrado no Drive: {drive_model_dir}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Google Drive n√£o montado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DetK9SjgBn_Q"
      },
      "outputs": [],
      "source": [
        "# @title 8Ô∏è‚É£ Infer√™ncia de Arquivo √önico\n",
        "\n",
        "# @markdown ### Caminhos\n",
        "INPUT_PATH = \"/content/drive/MyDrive/codename-rvc/inputs/audio.wav\"  # @param {type:\"string\"}\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/codename-rvc/outputs/output.wav\"  # @param {type:\"string\"}\n",
        "MODEL_PATH = \"logs/meu_modelo/meu_modelo.pth\"  # @param {type:\"string\"}\n",
        "INDEX_PATH = \"logs/meu_modelo/added_meu_modelo.index\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Configura√ß√µes\n",
        "PITCH = 0  # @param {type:\"slider\", min:-24, max:24, step:1}\n",
        "F0_METHOD = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\"]\n",
        "INDEX_RATE = 0.5  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "PROTECT = 0.33  # @param {type:\"slider\", min:0.0, max:0.5, step:0.05}\n",
        "\n",
        "SPLIT_AUDIO = False  # @param {type:\"boolean\"}\n",
        "CLEAN_AUDIO = False  # @param {type:\"boolean\"}\n",
        "F0_AUTOTUNE = False  # @param {type:\"boolean\"}\n",
        "EXPORT_FORMAT = \"WAV\"  # @param [\"WAV\", \"MP3\", \"FLAC\", \"OGG\", \"M4A\"]\n",
        "\n",
        "print(f\"üéµ Input: {INPUT_PATH}\")\n",
        "print(f\"üíæ Output: {OUTPUT_PATH}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Criar pasta de sa√≠da se n√£o existir\n",
        "from pathlib import Path\n",
        "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "!python core.py infer \\\n",
        "    --input_path \"{INPUT_PATH}\" \\\n",
        "    --output_path \"{OUTPUT_PATH}\" \\\n",
        "    --pth_path \"{MODEL_PATH}\" \\\n",
        "    --index_path \"{INDEX_PATH}\" \\\n",
        "    --pitch {PITCH} \\\n",
        "    --f0_method \"{F0_METHOD}\" \\\n",
        "    --index_rate {INDEX_RATE} \\\n",
        "    --protect {PROTECT} \\\n",
        "    --split_audio {str(SPLIT_AUDIO)} \\\n",
        "    --clean_audio {str(CLEAN_AUDIO)} \\\n",
        "    --f0_autotune {str(F0_AUTOTUNE)} \\\n",
        "    --export_format \"{EXPORT_FORMAT}\"\n",
        "\n",
        "print(f\"\\n‚úÖ Salvo em: {OUTPUT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8CAj5VZxBn_Q"
      },
      "outputs": [],
      "source": [
        "# @title 9Ô∏è‚É£ Infer√™ncia em Lote\n",
        "\n",
        "INPUT_FOLDER = \"/content/drive/MyDrive/codename-rvc/inputs/\"  # @param {type:\"string\"}\n",
        "OUTPUT_FOLDER = \"/content/drive/MyDrive/codename-rvc/outputs/\"  # @param {type:\"string\"}\n",
        "MODEL_PATH = \"logs/meu_modelo/meu_modelo.pth\"  # @param {type:\"string\"}\n",
        "INDEX_PATH = \"logs/meu_modelo/added_meu_modelo.index\"  # @param {type:\"string\"}\n",
        "\n",
        "PITCH = 0  # @param {type:\"slider\", min:-24, max:24, step:1}\n",
        "F0_METHOD = \"rmvpe\"  # @param [\"crepe\", \"crepe-tiny\", \"rmvpe\", \"fcpe\"]\n",
        "INDEX_RATE = 0.5  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "EXPORT_FORMAT = \"WAV\"  # @param [\"WAV\", \"MP3\", \"FLAC\", \"OGG\", \"M4A\"]\n",
        "\n",
        "import os\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Input: {INPUT_FOLDER}\")\n",
        "print(f\"üìÇ Output: {OUTPUT_FOLDER}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python core.py batch_infer \\\n",
        "    --input_folder \"{INPUT_FOLDER}\" \\\n",
        "    --output_folder \"{OUTPUT_FOLDER}\" \\\n",
        "    --pth_path \"{MODEL_PATH}\" \\\n",
        "    --index_path \"{INDEX_PATH}\" \\\n",
        "    --pitch {PITCH} \\\n",
        "    --f0_method \"{F0_METHOD}\" \\\n",
        "    --index_rate {INDEX_RATE} \\\n",
        "    --export_format \"{EXPORT_FORMAT}\"\n",
        "\n",
        "print(f\"\\n‚úÖ Arquivos convertidos em: {OUTPUT_FOLDER}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}